#+STARTUP: showall

* Chapter 4: Probability Distributions
** 4.1 Random Variables
   Random variables are essentially a collection of things that have a
   random chance of happening. In the book's example, we look at
   preferred attributes for a car. Keep in mind that the probability
   of a group of things happening is the probabilities of all of the
   events added together. For example: if we were to take M (mileage),
   and P (price), then list the cars as C with their relative
   probability, and rank them by number (1 being preferred):

      Proabability table
   |----+----+----+------|
   | M  | P  | C  | Prob |
   |----+----+----+------|
   | M1 | P1 | C1 | 0.03 |
   |    |    | C2 | 0.06 |
   |    |    | C3 | 0.07 |
   |    | P2 | C1 | 0.02 |
   |    |    | C2 | 0.01 |
   |    |    | C3 | 0.01 |
   | M2 | P1 | C1 | 0.09 |
   |    |    | C2 | 0.16 |
   |    |    | C3 | 0.10 |
   |    | P2 | C1 | 0.02 |
   |    |    | C2 | 0.07 |
   |    |    | C3 | 0.06 |
   | M3 | P1 | C1 | 0.05 |
   |    |    | C2 | 0.05 |
   |    |    | C3 | 0.14 |
   |    | P2 | C1 | 0.01 |
   |    |    | C2 | 0.03 |
   |    |    | C3 | 0.02 |
   |----+----+----+------|

   We can see that the cars with 0 preferred attributes have
   probabilities of 0.07, 0.06, 0.03, and 0.02. The probability of
   getting no preferred attributes is 0.07+0.06+0.03+0.02 = 0.29.

   All of the values in the "Prob" column are *random
   variables*. Random variables are denoted using capital letters. The
   *probability distribution* of a group of variables is f(x) = P(X =
   x) or the probability that the random variable will be equal to the
   expected value. *Discrete random variables* are of a finite
   number/countable infinity of values. *Continuous random variables*
   are infinite (I think). The sum of the probabilities of all X in a
   proabability distribution will always equal 1.
** 4.2 The Binomial Distribution
   When we are testing the probability of an outcome, we perform a set
   of repeated tests called *trials*. We are interested in getting x
   *successes* from the n *trials*. A *Bernoulli trial* is a trial in
   which the following conditions are true:
   1) *There are only two possible outcomes for each trial*
   2) *The probability of success is the same for each trial*
   3) *The outcomes from different trials are independent*
   Additionally, we can add the assumption that
   4) *There are a fixed number n of Bernoulli trials conducted*
*** Binomial probability distribution n = 3
**** Example
     Imagine a relay tower that you have to repair within an hour,
     and the probability that it can be repaired in that time is 0.9.
     1) List all of the possible outcomes in terms of Success and
        Failure.
     2) Find the probability distribution of the number of successes
        among the n repairs. In this case, n = 3.
     And so we begin.
     1) We use F to denote failure and S to denote success.
        The possible outcomes are
        |-----+-----+-----+-----|
        | X=0 | X=1 | X=2 | X=3 |
        |-----+-----+-----+-----|
        | FFF | FFS | FSS | SSS |
        |     | FSF | SFS |     |
        |     | SFF | SSF |     |
        |-----+-----+-----+-----|
     2) The results of each are independent. The number of outcomes
        for X = n is just 3cn (3 choose n). So the probability of
        X = 0 is   0.1 x 0.1 x 0.1  = 0.001
        X = 1 is 3(0.1 x 0.1 x 0.9) = 0.027
        X = 2 is 3(0.1 x 0.9 x 0.9) = 0.243
        X = 3 is   0.9 x 0.9 x 0.9  = 0.729
        These probabilities can be expressed by a formula that I can't
        really type here. It's in the book.

  The probability distribution is called the *binomial
  distribution* because the probabilities are the terms of the
  binomial expansion of [p+(1-p)]^n. This is also why the nCx stuff
  is referred to as *binomial coefficient*. The *binomial
  distribution* formula is
     b(x; n,p) = nCx (p^x)(1-p)^(n-x)
  It's got to do with... uh... stuff.
